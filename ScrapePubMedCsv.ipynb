{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_ontology(\"http://www.semanticweb.org/lauramiron/ontologies/2019/1/merged-research-mentor#\")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "import pandas as pd\n",
    "import datetime, math\n",
    "onto = get_ontology('new-ResearchMentor.owl')\n",
    "vivoNS = onto.get_namespace(\"http://vivoweb.org/ontology/core\")\n",
    "meshNS = onto.get_namespace(\"http://phenomebrowser.net/ontologies/mesh/mesh.owl#\")\n",
    "onto.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pmids_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indiv(onto,name):\n",
    "    return onto.search_one(iri='*'+name)\n",
    "\n",
    "def month_to_int(month):\n",
    "    months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    return int(months.index(month) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto.save('new-ResearchMentor.owl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-12\n",
      "2015-03-15\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-14\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-14\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n",
      "2019-02-12\n"
     ]
    }
   ],
   "source": [
    "articles = onto.search(type=vivoNS.AcademicArticle)\n",
    "for article in articles:\n",
    "    if not article.datePublished: continue\n",
    "    year, month, day = article.datePublished.split('-')\n",
    "    article.datePublished = datetime.date(int(year),int(month),int(day))\n",
    "    print(article.datePublished)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2af7f5d36182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marticle_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshKeyword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marticle_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshKeyword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmesh_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marticle_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshKeyword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0monto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/owlready2/namespace.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file, format, **kargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rdfxml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mif\u001b[0m   \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_onto_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_iri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_LOG_LEVEL\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"* Owlready2 * Saving ontology %s to %s...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"???\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/owlready2/namespace.py\u001b[0m in \u001b[0;36m_open_onto_file\u001b[0;34m(base_iri, name, mode, only_local)\u001b[0m\n\u001b[1;32m    810\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0monly_local\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_iri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monto_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s.owl\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m   \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "for index, row in df.iterrows():\n",
    "    pmid = row['pmid']\n",
    "    article_i = find_indiv(onto,str(pmid))\n",
    "    if (article_i):\n",
    "        mesh = row['mesh']\n",
    "        year = row['year']\n",
    "        month = row['month']\n",
    "        day = row['day']\n",
    "        journal = row['journal']\n",
    "        journal_i = find_indiv(onto,'PubMedArticle'+str(pmid))\n",
    "        if not journal_i: journal_i = vivoNS.AcademicArticle('PubMedArticle'+str(pmid))\n",
    "        \n",
    "        article_i.pmid = pmid\n",
    "        if day and (not math.isnan(day)) and month and (month in months) and year and (not math.isnan(year)):\n",
    "            pydate = datetime.date(year,month_to_int(month),int(day))\n",
    "            xsddate = pydate.isoformat()\n",
    "            article_i.datePublished = xsddate\n",
    "        article_i.hasPublicationVenue = [journal_i]\n",
    "        \n",
    "        mesh_i = onto.search_one(iri=\"*\"+mesh)\n",
    "        if mesh_i:\n",
    "            if not article_i.meshKeyword: article_i.meshKeyword = [mesh_i]\n",
    "            else: article_i.meshKeyword.append(mesh_i)\n",
    "onto.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_sub_org(sub_org):\n",
    "    for pfx in org_prefixes:\n",
    "        if sub_org.startswith(pfx):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "def add_sub_org(onto,sub_org):\n",
    "    if sub_org.startswith('Departmentof'):\n",
    "        sub_org = 'Stanford'+sub_org.strip('Departmentof')+'Department'\n",
    "        if len(onto.search(iri='*'+sub_org)) == 0:\n",
    "            sub_org_indiv = vivoNS.AcademicDepartment(sub_org)\n",
    "            sub_org_indiv.subOrganizationWithin.append(school_indiv)\n",
    "    elif sub_org.startswith('Divisionof'):\n",
    "        sub_org = 'Stanford'+sub_org\n",
    "        if len(onto.search(iri='*'+sub_org)) == 0:\n",
    "            sub_org_indiv = vivoNS.Division(sub_org)\n",
    "            sub_org_indiv.subOrganizationWithin.append(school_indiv)\n",
    "    elif sub_org.startswith('Centerfor'):\n",
    "        sub_org = 'Stanford' + sub_org\n",
    "        if len(onto.search(iri='*'+sub_org)) == 0:\n",
    "            sub_org_indiv = vivoNS.Center(sub_org)\n",
    "            sub_org_indiv.subOrganizationWithin.append(school_indiv) \n",
    "\n",
    "def add_all_sub_orgs(onto,sub_org):\n",
    "    print(sub_org)\n",
    "    sub_sub_orgs = sub_org.split('and')\n",
    "    first_com = sub_sub_orgs[0]\n",
    "    if len(sub_sub_orgs) == 1:\n",
    "        return add_sub_org(onto,first_com)\n",
    "    for i in range(1,len(sub_sub_orgs)):\n",
    "        if (is_sub_org(sub_sub_orgs[i])):\n",
    "            add_sub_org(onto,first_com)\n",
    "            add_all_sub_orgs(onto,sub_org[len(first_com)+3:])\n",
    "            break\n",
    "        else:\n",
    "            first_com += 'and'\n",
    "            first_com += sub_sub_orgs[i]\n",
    "    add_sub_org(onto,first_com)\n",
    "            \n",
    "# add MESH terms and PubMed articles\n",
    "org_prefixes = ['Departmentof','Divisionof','Centerof']\n",
    "df = pd.read_csv('authors_cleaned.csv',sep=',',skipinitialspace=True,quoting=csv.QUOTE_ALL,engine='python')\n",
    "for aff in df.afft.unique():\n",
    "    if not 'Stanford University' in aff: continue\n",
    "    locs = aff.split(',')\n",
    "    if len(locs) < 1: continue\n",
    "    if len(locs) == 1: \n",
    "        school = locs[0].strip()\n",
    "        continue\n",
    "    else:\n",
    "        sub_org = locs[0].strip()\n",
    "        school = locs[1].strip()\n",
    "    if school == 'Stanford University':\n",
    "        school_indiv = onto.search(iri='*StanfordUniversity')[0]\n",
    "    elif school in ('School of Medicine at Stanford University','Stanford University School of Medicine'):\n",
    "        school_indiv = onto.search(iri='*StanfordUniversitySchoolofMedicine')[0]\n",
    "    elif school in ('Stanford University Medical Center'):\n",
    "        school_indiv = onto.search(iri='*StanfordUniversityMedicalCenter')[0]\n",
    "    else: continue #not affiliated with Stanford\n",
    "        \n",
    "    sub_org = sub_org.split('(')[0].split('-')[0].replace(' ','').strip('1]').replace('&','and').replace('/','and').split(';')[0]\n",
    "    add_all_sub_orgs(onto,sub_org)\n",
    "    \n",
    "onto.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_prefixes = ['Departmentof','Divisionof','Centerof']\n",
    "\n",
    "def parse_sub_org(aff):\n",
    "    if not 'Stanford University' in aff: return None\n",
    "    locs = aff.split(',')\n",
    "    if len(locs) < 1: return None\n",
    "    elif len(locs) == 1: return 'StanfordUniversity'\n",
    "    else:\n",
    "        sub_org = locs[0].strip()\n",
    "        sub_org = sub_org.split('(')[0].split('-')[0].replace(' ','').strip('1]').replace('&','and').replace('/','and').split(';')[0]\n",
    "        return sub_org\n",
    "\n",
    "def is_sub_org(sub_org):\n",
    "    for pfx in org_prefixes:\n",
    "        if sub_org.startswith(pfx):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "def get_sub_org(onto,sub_org,orgs_list):\n",
    "#     print(orgs_list)\n",
    "    if sub_org.startswith('Departmentof'):\n",
    "        sub_org = 'Stanford'+sub_org.strip('Departmentof')+'Department'\n",
    "    elif sub_org.startswith('Divisionof'):\n",
    "        sub_org = 'Stanford'+sub_org\n",
    "    elif sub_org.startswith('Centerfor'):\n",
    "        sub_org = 'Stanford' + sub_org\n",
    "    else: return\n",
    "    indiv = onto.search_one(iri='*'+sub_org)\n",
    "    print(indiv)\n",
    "    orgs_list.append(indiv)\n",
    "                            \n",
    "def get_all_sub_orgs(onto,sub_org,orgs_list):\n",
    "    sub_sub_orgs = sub_org.split('and')\n",
    "    first_com = sub_sub_orgs[0]\n",
    "    if len(sub_sub_orgs) == 1:\n",
    "        return get_sub_org(onto,first_com,orgs_list)\n",
    "    for i in range(1,len(sub_sub_orgs)):\n",
    "        if (is_sub_org(sub_sub_orgs[i])):\n",
    "            get_sub_org(onto,first_com,orgs_list)\n",
    "            get_all_sub_orgs(onto,sub_org[len(first_com)+3:],orgs_list)\n",
    "            break\n",
    "        else:\n",
    "            first_com += 'and'\n",
    "            first_com += sub_sub_orgs[i]\n",
    "    get_sub_org(onto,first_com,orgs_list)\n",
    "\n",
    "\n",
    "df = pd.read_csv('authors_cleaned.csv',sep=',',skipinitialspace=True,quoting=csv.QUOTE_ALL,engine='python')\n",
    "for index, line in df.iterrows():\n",
    "    print(index)\n",
    "    author = line['author']\n",
    "    pmid = line['pmid']\n",
    "    afft = line['afft']\n",
    "    first_name = author.split(' ')[0]\n",
    "    last_name = author.split(' ')[1]\n",
    "    faculty_indiv = onto.search_one(iri='*'+first_name+last_name)\n",
    "    if not faculty_indiv: faculty_indiv = onto.search_one(iri='*'+author.replace(' ',''))\n",
    "    if not faculty_indiv: continue\n",
    "    \n",
    "#     print(author)\n",
    "    sub_orgs = []\n",
    "    sub_org_str = parse_sub_org(afft)\n",
    "    if (sub_org_str == None): continue\n",
    "    get_all_sub_orgs(onto,sub_org_str,sub_orgs)\n",
    "    for sub_org in sub_orgs:\n",
    "        try:\n",
    "            if sub_org == None:\n",
    "                sub_org = onto.search_one(iri='*StanfordUniversity')\n",
    "    #         print(sub_org)\n",
    "            if not sub_org in faculty_indiv.currentMemberOf:\n",
    "                faculty_indiv.currentMemberOf.append(sub_org)\n",
    "            article_name = 'PubMedArticle'+str(pmid)\n",
    "            article_indiv = onto.search_one(iri='*'+article_name)\n",
    "            if not article_indiv:\n",
    "                article_indiv = vivoNS.AcademicArticle(article_name)\n",
    "                article_indiv.pmid = pmid\n",
    "            if article_indiv not in faculty_indiv.authorOf:\n",
    "                faculty_indiv.authorOf.append(article_indiv)\n",
    "        except:\n",
    "            continue\n",
    "onto.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('old/results','r') as f:\n",
    "    lines = f.readlines()\n",
    "    inserts = 0\n",
    "    for line in lines:\n",
    "        if any(c.isalpha() for c in line):\n",
    "            print(line)\n",
    "            inserts += 1\n",
    "print('Inserted data for '+str(inserts)+' person-pubMed relationships '+str(len(lines)-inserts)+' PubMed records')\n",
    "print('Added 10 pubmed articles for students and 144 for faculty members')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
